{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import numpy as np\n","import copy\n","import matplotlib.pyplot as plt\n","import sklearn\n","import sklearn.datasets\n","import sklearn.linear_model"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def sigmoid(z):\n","    \n","    s = 1 / (1 + np.exp(-z))\n","    return s"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def layer_sizes(X, Y):\n","    \n","    n_x = X.shape[0]\n","    n_h = 4\n","    n_y = Y.shape[0]\n","    return (n_x, n_h, n_y)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def initialize_parameters(n_x, n_h, n_y):\n","\n","    W1 = np.random.randn(n_h,n_x) * 0.01\n","    b1 = np.zeros((n_h,1))\n","    W2 = np.random.randn(n_y,n_h) * 0.01\n","    b2 = np.zeros((n_y,1))\n","\n","    parameters = {\"W1\": W1,\n","                  \"b1\": b1,\n","                  \"W2\": W2,\n","                  \"b2\": b2}\n","    \n","    return parameters\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def forward_propagation(X, parameters):\n","    \n","    W1 = parameters[\"W1\"]\n","    b1 = parameters[\"b1\"]\n","    W2 = parameters[\"W2\"]\n","    b2 = parameters[\"b2\"]\n","\n","    Z1 = np.dot(W1,X) + b1\n","    A1 = np.tanh(Z1)\n","    Z2 = np.dot(W2,A1) + b2\n","    A2 = sigmoid(Z2)\n","\n","    assert(A2.shape == (1, X.shape[1]))\n","    \n","    cache = {\"Z1\": Z1,\n","             \"A1\": A1,\n","             \"Z2\": Z2,\n","             \"A2\": A2}\n","    \n","    return A2, cache"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def compute_cost(A2, Y):\n","    \n","    m = Y.shape[1]\n","\n","    logprobs = np.multiply(Y ,np.log(A2)) + np.multiply((1-Y), np.log(1-A2))\n","    cost = (-1/m) * np.sum(logprobs)\n","\n","    cost = float(np.squeeze(cost))\n","\n","    return cost"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def backward_propagation(parameters, cache, X, Y):\n","\n","    m = X.shape[1]\n","\n","    W1 = parameters[\"W1\"]\n","    W2 = parameters[\"W2\"]\n","\n","    A1 = cache[\"A1\"]\n","    A2 = cache[\"A2\"]\n","\n","    dZ2 = A2 - Y\n","    dW2 = (1/m) * np.dot(dZ2,A1.T)\n","    db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True)\n","    dZ1 = np.dot(W2.T, dZ2) * (1 - np.power(A1, 2))\n","    dW1 = (1/m) * np.dot (dZ1, X.T)\n","    db1 = (1/m) * np.sum(dZ1, axis=1, keepdims=True)\n","\n","    grads = {\"dW1\": dW1,\n","             \"db1\": db1,\n","             \"dW2\": dW2,\n","             \"db2\": db2}\n","    \n","    return grads"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def update_parameters(parameters, grads, learning_rate = 1.2):\n","\n","    W1 = parameters[\"W1\"]\n","    b1 = parameters[\"b1\"]\n","    W2 = parameters[\"W2\"]\n","    b2 = parameters[\"b2\"]\n","\n","    dW1 = grads[\"dW1\"]\n","    db1 = grads[\"db1\"]\n","    dW2 = grads[\"dW2\"]\n","    db2 = grads[\"db2\"]\n","\n","    W1 = W1 - learning_rate * dW1\n","    b1 = b1 - learning_rate * db1\n","    W2 = W2 - learning_rate * dW2\n","    b2 = b2 - learning_rate * db2\n","\n","    parameters = {\"W1\": W1,\n","                  \"b1\": b1,\n","                  \"W2\": W2,\n","                  \"b2\": b2}\n","    \n","    return parameters"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def nn_model(X, Y, n_h, num_iterations = 10000, print_cost=False):\n","\n","    np.random.seed(3)\n","    n_x = layer_sizes(X, Y)[0]\n","    n_y = layer_sizes(X, Y)[2]\n","\n","    parameters = initialize_parameters(n_x, n_h, n_y)\n","\n","    W1 = parameters[\"W1\"]\n","    b1 = parameters[\"b1\"]\n","    W2 = parameters[\"W2\"]\n","    b2 = parameters[\"b2\"]\n","\n","    for i in range(0, num_iterations):\n","\n","        A2, cache = forward_propagation(X, parameters)\n","        cost = compute_cost(A2, Y)\n","        grads = backward_propagation(parameters, cache, X, Y)\n","        parameters = update_parameters(parameters, grads)\n","\n","        if print_cost and i % 1000 == 0:\n","            print (\"Cost after iteration %i: %f\" %(i, cost))\n","    \n","    return parameters"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def predict(parameters, X):\n","\n","    A2, cache = forward_propagation(X, parameters)\n","    predictions = (A2 > 0.5)\n","\n","    return predictions\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# parameters = nn_model(X, Y, n_h = 4, num_iterations = 10000, print_cost=True)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"d3ee1eecf4f60a39431daf7cc73333bba67933358b7f9d243b4a5c4aa9fb0709"}}},"nbformat":4,"nbformat_minor":2}
